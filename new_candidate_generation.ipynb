{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3\n",
      "1    5\n",
      "2    6\n",
      "3    1\n",
      "4    1\n",
      "5    8\n",
      "6    6\n",
      "7    4\n",
      "8    1\n",
      "9    1\n",
      "Name: predict_labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv(\n",
    "    'data/u.user', sep='|', names=users_cols, encoding='latin-1')\n",
    "\n",
    "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(\n",
    "    'data/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')\n",
    "\n",
    "# The movies file contains a binary feature for each genre.\n",
    "genre_cols = [\n",
    "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\",\n",
    "]\n",
    "movies_cols = [\n",
    "    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
    "] + genre_cols\n",
    "movies = pd.read_csv(\n",
    "    'data/u.item', sep='|', names=movies_cols, encoding='latin-1')\n",
    "\n",
    "# Since the ids start at 1, we shift them to start at 0.\n",
    "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\n",
    "ratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: str(x-1))\n",
    "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))\n",
    "\n",
    "\n",
    "genre_occurences = movies[genre_cols].sum().to_dict()\n",
    "\n",
    "genres_encoded = {x: i for i, x in enumerate(genre_cols)}\n",
    "\n",
    "\n",
    "\n",
    "def get_genres(movies, genres):\n",
    "    def get_all_genres(gs):\n",
    "        active = [str(genres_encoded[genre]) for genre, g in zip(genres, gs) if g==1]\n",
    "        if len(active) == 0:\n",
    "            return '0'\n",
    "        return ','.join((active))\n",
    "    movies['all_genres'] = [\n",
    "        get_all_genres(gs) for gs in zip(*[movies[genre] for genre in genres])]\n",
    "\n",
    "get_genres(movies, genre_cols) # 각 유저가 본 장르 얻기\n",
    "\n",
    "rating_details_sample = ratings.merge(movies, on='movie_id').merge(users, on='user_id')\n",
    "\n",
    "rating_details_sample['user_id']=rating_details_sample['user_id'].astype(int)\n",
    "rating_details_sample['movie_id']=rating_details_sample['movie_id'].astype(int)\n",
    "rating_details_sample=rating_details_sample.set_index(['user_id','unix_timestamp']).sort_index()\n",
    "rating_details_sample =rating_details_sample.reset_index()\n",
    "\n",
    "rating_details_sample['movie_type']=np.where(rating_details_sample['rating'] >= 3, 'like', 'dislike') # 3보다 크면 like\n",
    "rating_details_sample['movie_name']=rating_details_sample['title'].str[:-6] # 년도 부분 자르기\n",
    "\n",
    "user_ids = rating_details_sample[\"user_id\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "movie_ids = rating_details_sample[\"movie_id\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "\n",
    "\n",
    "title_ids = rating_details_sample[\"movie_name\"].unique().tolist()\n",
    "title2title_encoded = {x: i for i, x in enumerate(title_ids)}\n",
    "title_encoded2title = {i: x for i, x in enumerate(title_ids)}\n",
    "\n",
    "rating_details_sample[\"user\"] = rating_details_sample[\"user_id\"].map(user2user_encoded)\n",
    "rating_details_sample[\"movie\"] = rating_details_sample[\"movie_id\"].map(movie2movie_encoded)\n",
    "rating_details_sample[\"title_d\"] = rating_details_sample[\"movie_name\"].map(title2title_encoded)\n",
    "\n",
    "sample_data=rating_details_sample[['user','occupation','sex']]\n",
    "sample_data=sample_data.reset_index()\n",
    "\n",
    "movie_list = rating_details_sample.groupby(['user','movie_type'])['movie'].apply(list).reset_index()\n",
    "title_list = rating_details_sample.groupby(['user'])['title_d'].apply(list).reset_index()\n",
    "genre_list = rating_details_sample.groupby(['user'])['all_genres'].unique().apply(list).reset_index()\n",
    "\n",
    "# Get the unique set of genre for all the users\n",
    "genre_list['all_genres']=genre_list['all_genres'].apply(lambda x: list(set(','.join(x))) ) # 중복제거\n",
    "genre_list['all_genres']=genre_list['all_genres'].apply(lambda x:[ x for x in x if x.isdigit() ])\n",
    "\n",
    "user_video_list = movie_list.pivot(index='user', columns='movie_type', values='movie').reset_index()\n",
    "user_video_list.fillna(rating_details_sample[\"movie\"].max()+1, inplace=True)\n",
    "\n",
    "sample_data = sample_data.drop('index',axis=1)\n",
    "sample_data = sample_data.drop_duplicates()\n",
    "\n",
    "user_final_list = pd.merge(user_video_list,title_list, how= 'left')\n",
    "user_title_list1 = pd.merge(user_final_list,genre_list, how='left')\n",
    "user_title_list = pd.merge(user_title_list1,sample_data, how='left')\n",
    "\n",
    "user_title_list['like'] =user_title_list['like'].apply(lambda x: x if type(x) is list else [x])\n",
    "user_title_list['dislike'] =user_title_list['dislike'].apply(lambda x: x if type(x) is list else [x])\n",
    "user_title_list['predict_labels'] = user_title_list['like'].apply(lambda x: (x[-1])) #label을 마지막 값으로..\n",
    "user_title_list['like']=user_title_list['like'].apply(lambda x: (x[:-1]))\n",
    "\n",
    "user_title_list['predict_labels'] = user_title_list['predict_labels'].apply(lambda x: 1 if x == 10 else x)\n",
    "print(user_title_list['predict_labels'])\n",
    "user_title_list_e=user_title_list[(user_title_list.user >= 1)&\n",
    "                                  (user_title_list.user <= 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       [4, 5]\n",
       "2       [0, 6]\n",
       "3          [6]\n",
       "4          [7]\n",
       "5          [8]\n",
       "6       [5, 6]\n",
       "7    [2, 9, 4]\n",
       "8          [9]\n",
       "9          [9]\n",
       "Name: title_d, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_title_list_e['title_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5\n",
       "2    6\n",
       "3    1\n",
       "4    1\n",
       "5    8\n",
       "6    6\n",
       "7    4\n",
       "8    1\n",
       "9    1\n",
       "Name: predict_labels, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_title_list_e['predict_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          176       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 465\n",
      "Trainable params: 465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_class = rating_details_sample[\"movie\"].max() + 2\n",
    "embedding_dims = 16\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim=num_class, output_dim=embedding_dims, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.4444\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.4444\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.4444\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 943us/step - loss: 0.6076 - accuracy: 0.4444\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 810us/step - loss: 0.5835 - accuracy: 0.4444\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.4444\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.4444\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.4444\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.4444\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.4444\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.4444\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.4444\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 786us/step - loss: 0.3955 - accuracy: 0.4444\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 926us/step - loss: 0.3718 - accuracy: 0.4444\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.4444\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 956us/step - loss: 0.3237 - accuracy: 0.4444\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 786us/step - loss: 0.2993 - accuracy: 0.4444\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 855us/step - loss: 0.2746 - accuracy: 0.4444\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.4444\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 875us/step - loss: 0.2245 - accuracy: 0.4444\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 788us/step - loss: 0.1990 - accuracy: 0.4444\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.4444\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.1465 - accuracy: 0.4444\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 872us/step - loss: 0.1195 - accuracy: 0.4444\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.4444\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 856us/step - loss: 0.0641 - accuracy: 0.4444\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 946us/step - loss: 0.0356 - accuracy: 0.4444\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 822us/step - loss: 0.0066 - accuracy: 0.4444\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: -0.0230 - accuracy: 0.4444\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: -0.0532 - accuracy: 0.4444\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 797us/step - loss: -0.0839 - accuracy: 0.4444\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: -0.1155 - accuracy: 0.4444\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: -0.1477 - accuracy: 0.4444\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 887us/step - loss: -0.1806 - accuracy: 0.4444\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 765us/step - loss: -0.2141 - accuracy: 0.4444\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: -0.2485 - accuracy: 0.4444\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 800us/step - loss: -0.2836 - accuracy: 0.4444\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: -0.3196 - accuracy: 0.4444\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 901us/step - loss: -0.3565 - accuracy: 0.4444\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 837us/step - loss: -0.3943 - accuracy: 0.4444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x645956828>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(tf.keras.preprocessing.sequence.pad_sequences(user_title_list_e['title_d']),\n",
    "                    user_title_list_e['predict_labels'].values,\n",
    "                    epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_details_sample[\"movie\"].max() + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
