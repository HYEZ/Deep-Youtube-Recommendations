{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# data 읽기\n",
    "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv(\n",
    "    'data/u.user', sep='|', names=users_cols, encoding='latin-1')\n",
    "\n",
    "watch_cols = ['user_id', 'movie_id', 'watch_hist_time']\n",
    "watches = pd.read_csv(\n",
    "    'data/u.watch', sep='\\t', names=watch_cols, encoding='latin-1')\n",
    "\n",
    "search_cols = ['user', 'search_hist']\n",
    "searches = pd.read_csv(\n",
    "    'data/u.search', sep='\\t', names=search_cols, encoding='latin-1')\n",
    "\n",
    "# The movies file contains a binary feature for each genre.\n",
    "genre_cols = [\n",
    "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\",\n",
    "]\n",
    "movies_cols = [\n",
    "    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
    "] + genre_cols\n",
    "movies = pd.read_csv(\n",
    "    'data/u.item', sep='|', names=movies_cols, encoding='latin-1')\n",
    "\n",
    "# Since the ids start at 1, we shift them to start at 0.\n",
    "# users[\"user_id\"] = users[\"user_id\"].apply(lambda x: str(x-1))\n",
    "# movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\n",
    "# watches[\"movie_id\"] = watches[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "# watches[\"user_id\"] = watches[\"user_id\"].apply(lambda x: str(x-1))\n",
    "# searches[\"user_id\"] = searches[\"user\"].apply(lambda x: str(x-1))\n",
    "\n",
    "# example_age 추가\n",
    "movies['example_age'] = (pd.to_datetime(\"now\") - pd.to_datetime(movies['release_date']))\\\n",
    "            /np.timedelta64(1,'D') \n",
    "\n",
    "# normalize\n",
    "def normalize_col(df,col_name):\n",
    "    df[col_name] = (df[col_name] - df[col_name].min()) / (df[col_name].max() - df[col_name].min())\n",
    "    return df\n",
    "\n",
    "movies = normalize_col(movies,'example_age')\n",
    "watches = normalize_col(watches,'watch_hist_time')\n",
    "\n",
    "\n",
    "# data 합치기\n",
    "data = watches.merge(movies, on='movie_id').merge(users, on='user_id')\n",
    "data['user_id']=data['user_id'].astype(int)\n",
    "data['movie_id']=data['movie_id'].astype(int)\n",
    "data = data.set_index(['user_id']).sort_index()\n",
    "data = data.reset_index()\n",
    "data['movie_name']=data['title'].str[:-6] # 년도 부분 자르기\n",
    "\n",
    "\n",
    "# occupation 인코딩\n",
    "occupations = data[\"occupation\"].unique().tolist()\n",
    "occupations_encoded = {x: i for i, x in enumerate(occupations)}\n",
    "occupationsencoded2occupations = {i: x for i, x in enumerate(occupations)}\n",
    "\n",
    "# search history 인코딩\n",
    "search_hists = searches[\"search_hist\"].unique().tolist()\n",
    "search_encoded = {x: i for i, x in enumerate(search_hists)}\n",
    "searchencoded2search = {i: x for i, x in enumerate(search_hists)}\n",
    "\n",
    "# 유저 인덱스 인코딩\n",
    "user_ids = data[\"user_id\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "# 영화 인덱스 인코딩\n",
    "movie_ids = data[\"movie_id\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "\n",
    "# 영화 제목 인코딩\n",
    "title_ids = data[\"title\"].unique().tolist()\n",
    "title2title_encoded = {x: i for i, x in enumerate(title_ids)}\n",
    "title_encoded2title = {i: x for i, x in enumerate(title_ids)}\n",
    "\n",
    "# 인코딩으로 바꾸기\n",
    "data[\"user\"] = data[\"user_id\"].map(user2user_encoded)\n",
    "data[\"movie\"] = data[\"movie_id\"].map(movie2movie_encoded)\n",
    "data[\"title_d\"] = data[\"title\"].map(title2title_encoded)\n",
    "searches[\"search_hist\"] = searches[\"search_hist\"].map(search_encoded)\n",
    "data[\"occupation\"] = data[\"occupation\"].map(occupations_encoded)\n",
    "# searches[\"search_hist\"] = searches[\"search_hist\"]\n",
    "searches = normalize_col(searches,'search_hist')\n",
    "\n",
    "watch_hist = data.groupby(['user'])['movie_id'].apply(list).reset_index()\n",
    "search_hist = searches.groupby(['user'])['search_hist'].apply(list).reset_index()\n",
    "watch_hist_time = data.groupby(['user'])['watch_hist_time'].apply(list).reset_index()\n",
    "example_age = data.groupby(['user'])['example_age'].apply(list).reset_index()\n",
    "\n",
    "user_video_list = data.pivot(index='user_id', columns='movie_id', values='movie').reset_index()\n",
    "user_video_list.fillna(data[\"movie_id\"].max()+1, inplace=True)\n",
    "\n",
    "sample_data=data[['user','occupation','sex']]\n",
    "sample_data=sample_data.reset_index()\n",
    "sample_data = sample_data.drop('index',axis=1)\n",
    "sample_data = sample_data.drop_duplicates()\n",
    "\n",
    "user_movie_list = pd.merge(sample_data,watch_hist, how= 'left')\n",
    "user_movie_list = pd.merge(user_movie_list,watch_hist_time, how='left')\n",
    "user_movie_list = pd.merge(user_movie_list,search_hist, how='left')\n",
    "user_movie_list = pd.merge(user_movie_list,example_age, how='left')\n",
    "user_movie_list['search_hist'] = user_movie_list['search_hist'].apply(lambda x: x if type(x) is list else []) # NaN 처리\n",
    "user_movie_list['predict_labels'] = user_movie_list['movie_id'].apply(lambda x: int(random.uniform(0,data[\"movie\"].max()))) #label을 마지막 값으로..\n",
    "\n",
    "\n",
    "\n",
    "train_data = user_movie_list[(user_movie_list.user >= 1)&\n",
    "                                  (user_movie_list.user <= 5)]\n",
    "test_data = user_movie_list[(user_movie_list.user >= 6)&\n",
    "                                  (user_title_list.user <= 10)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>genre_unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>year</th>\n",
       "      <th>example_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (2011)</td>\n",
       "      <td>01-Jan-2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.359982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (2020)</td>\n",
       "      <td>01-Jan-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1998)</td>\n",
       "      <td>01-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.879969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Yao+a+yao+yao+dao+wai...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Twelve Monkeys (2018)</td>\n",
       "      <td>01-Jan-2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Twelve%20Monk...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.079947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Babe%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Dead Man Walking (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Dead%20Man%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Richard III (1995)</td>\n",
       "      <td>22-Jan-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Richard%20III...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.957726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              title release_date  \\\n",
       "0         1                                   Toy Story (1995)  01-Jan-1995   \n",
       "1         2                                   GoldenEye (2011)  01-Jan-2011   \n",
       "2         3                                  Four Rooms (2020)  01-Jan-2020   \n",
       "3         4                                  Get Shorty (1995)  01-Jan-1995   \n",
       "4         5                                     Copycat (1998)  01-Jan-1998   \n",
       "5         6  Shanghai Triad (Yao a yao yao dao waipo qiao) ...  01-Jan-1995   \n",
       "6         7                              Twelve Monkeys (2018)  01-Jan-2018   \n",
       "7         8                                        Babe (1995)  01-Jan-1995   \n",
       "8         9                            Dead Man Walking (1995)  01-Jan-1995   \n",
       "9        10                                 Richard III (1995)  22-Jan-1996   \n",
       "\n",
       "   video_release_date                                           imdb_url  \\\n",
       "0                 NaN  http://us.imdb.com/M/title-exact?Toy%20Story%2...   \n",
       "1                 NaN  http://us.imdb.com/M/title-exact?GoldenEye%20(...   \n",
       "2                 NaN  http://us.imdb.com/M/title-exact?Four%20Rooms%...   \n",
       "3                 NaN  http://us.imdb.com/M/title-exact?Get%20Shorty%...   \n",
       "4                 NaN  http://us.imdb.com/M/title-exact?Copycat%20(1998)   \n",
       "5                 NaN  http://us.imdb.com/Title?Yao+a+yao+yao+dao+wai...   \n",
       "6                 NaN  http://us.imdb.com/M/title-exact?Twelve%20Monk...   \n",
       "7                 NaN     http://us.imdb.com/M/title-exact?Babe%20(1995)   \n",
       "8                 NaN  http://us.imdb.com/M/title-exact?Dead%20Man%20...   \n",
       "9                 NaN  http://us.imdb.com/M/title-exact?Richard%20III...   \n",
       "\n",
       "   genre_unknown  Action  Adventure  Animation  Children  ...  Horror  \\\n",
       "0              0       0          0          1         1  ...       0   \n",
       "1              0       1          1          0         0  ...       0   \n",
       "2              0       0          0          0         0  ...       0   \n",
       "3              0       1          0          0         0  ...       0   \n",
       "4              0       0          0          0         0  ...       0   \n",
       "5              0       0          0          0         0  ...       0   \n",
       "6              0       0          0          0         0  ...       0   \n",
       "7              0       0          0          0         1  ...       0   \n",
       "8              0       0          0          0         0  ...       0   \n",
       "9              0       0          0          0         0  ...       0   \n",
       "\n",
       "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  year  \\\n",
       "0        0        0        0       0         0    0        0  1995   \n",
       "1        0        0        0       0         1    0        0  2011   \n",
       "2        0        0        0       0         1    0        0  2020   \n",
       "3        0        0        0       0         0    0        0  1995   \n",
       "4        0        0        0       0         1    0        0  1998   \n",
       "5        0        0        0       0         0    0        0  1995   \n",
       "6        0        0        0       1         0    0        0  2018   \n",
       "7        0        0        0       0         0    0        0  1995   \n",
       "8        0        0        0       0         0    0        0  1995   \n",
       "9        0        0        0       0         0    1        0  1996   \n",
       "\n",
       "   example_age  \n",
       "0     1.000000  \n",
       "1     0.359982  \n",
       "2     0.000000  \n",
       "3     1.000000  \n",
       "4     0.879969  \n",
       "5     1.000000  \n",
       "6     0.079947  \n",
       "7     1.000000  \n",
       "8     1.000000  \n",
       "9     0.957726  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 1160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies # 영화 정보 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>watch_hist_time</th>\n",
       "      <th>search_hist</th>\n",
       "      <th>example_age</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>[10, 3, 9, 5]</td>\n",
       "      <td>[0.024163568773234202, 0.0, 0.2131350681536555...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.9577264264593144, 0.0, 1.0, 0.8799693352316...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>[2, 7]</td>\n",
       "      <td>[0.007390688617454417, 0.1644538856434767]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.3599824772752163, 0.07994743182564888]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>[3, 8]</td>\n",
       "      <td>[0.17919100725792175, 0.2091520623119136]</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[0.017923526287838557]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[0.1614887590724022]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>[2, 8]</td>\n",
       "      <td>[0.4109134360063728, 0.17919100725792175]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.3599824772752163, 1.0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>[7, 10, 1]</td>\n",
       "      <td>[0.20477075588599752, 0.1644538856434767, 0.03...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.07994743182564888, 0.9577264264593144, 1.0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.4109134360063728]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.20069923880332802]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  occupation sex       movie_id  \\\n",
       "0     0           0   M  [10, 3, 9, 5]   \n",
       "1     1           1   F         [2, 7]   \n",
       "2     2           2   M         [3, 8]   \n",
       "3     3           0   M            [8]   \n",
       "4     4           1   F            [4]   \n",
       "5     5           3   M            [6]   \n",
       "6     6           4   M         [2, 8]   \n",
       "7     7           4   M     [7, 10, 1]   \n",
       "8     8           5   M            [1]   \n",
       "9     9           6   M            [1]   \n",
       "\n",
       "                                     watch_hist_time search_hist  \\\n",
       "0  [0.024163568773234202, 0.0, 0.2131350681536555...       [0.0]   \n",
       "1         [0.007390688617454417, 0.1644538856434767]  [0.0, 1.0]   \n",
       "2          [0.17919100725792175, 0.2091520623119136]       [0.5]   \n",
       "3                                              [1.0]       [1.0]   \n",
       "4                             [0.017923526287838557]          []   \n",
       "5                               [0.1614887590724022]          []   \n",
       "6          [0.4109134360063728, 0.17919100725792175]          []   \n",
       "7  [0.20477075588599752, 0.1644538856434767, 0.03...       [0.0]   \n",
       "8                               [0.4109134360063728]          []   \n",
       "9                              [0.20069923880332802]          []   \n",
       "\n",
       "                                         example_age  predict_labels  \n",
       "0  [0.9577264264593144, 0.0, 1.0, 0.8799693352316...               1  \n",
       "1          [0.3599824772752163, 0.07994743182564888]               7  \n",
       "2                                         [0.0, 1.0]               3  \n",
       "3                                              [1.0]               6  \n",
       "4                                              [1.0]               3  \n",
       "5                                              [1.0]               3  \n",
       "6                          [0.3599824772752163, 1.0]               4  \n",
       "7     [0.07994743182564888, 0.9577264264593144, 1.0]               4  \n",
       "8                                              [1.0]               0  \n",
       "9                                              [1.0]               0  "
      ]
     },
     "execution_count": 1161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>watch_hist_time</th>\n",
       "      <th>search_hist</th>\n",
       "      <th>example_age</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>[2, 7]</td>\n",
       "      <td>[0.007390688617454417, 0.1644538856434767]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.3599824772752163, 0.07994743182564888]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>[3, 8]</td>\n",
       "      <td>[0.17919100725792175, 0.2091520623119136]</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[0.017923526287838557]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[0.1614887590724022]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  occupation sex movie_id                             watch_hist_time  \\\n",
       "1     1           1   F   [2, 7]  [0.007390688617454417, 0.1644538856434767]   \n",
       "2     2           2   M   [3, 8]   [0.17919100725792175, 0.2091520623119136]   \n",
       "3     3           0   M      [8]                                       [1.0]   \n",
       "4     4           1   F      [4]                      [0.017923526287838557]   \n",
       "5     5           3   M      [6]                        [0.1614887590724022]   \n",
       "\n",
       "  search_hist                                example_age  predict_labels  \n",
       "1  [0.0, 1.0]  [0.3599824772752163, 0.07994743182564888]               7  \n",
       "2       [0.5]                                 [0.0, 1.0]               3  \n",
       "3       [1.0]                                      [1.0]               6  \n",
       "4          []                                      [1.0]               3  \n",
       "5          []                                      [1.0]               3  "
      ]
     },
     "execution_count": 1162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data # train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>watch_hist_time</th>\n",
       "      <th>search_hist</th>\n",
       "      <th>example_age</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>[2, 8]</td>\n",
       "      <td>[0.4109134360063728, 0.17919100725792175]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.3599824772752163, 1.0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>[7, 10, 1]</td>\n",
       "      <td>[0.20477075588599752, 0.1644538856434767, 0.03...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.07994743182564888, 0.9577264264593144, 1.0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.4109134360063728]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.20069923880332802]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  occupation sex    movie_id  \\\n",
       "6     6           4   M      [2, 8]   \n",
       "7     7           4   M  [7, 10, 1]   \n",
       "8     8           5   M         [1]   \n",
       "9     9           6   M         [1]   \n",
       "\n",
       "                                     watch_hist_time search_hist  \\\n",
       "6          [0.4109134360063728, 0.17919100725792175]          []   \n",
       "7  [0.20477075588599752, 0.1644538856434767, 0.03...       [0.0]   \n",
       "8                               [0.4109134360063728]          []   \n",
       "9                              [0.20069923880332802]          []   \n",
       "\n",
       "                                      example_age  predict_labels  \n",
       "6                       [0.3599824772752163, 1.0]               4  \n",
       "7  [0.07994743182564888, 0.9577264264593144, 1.0]               4  \n",
       "8                                           [1.0]               0  \n",
       "9                                           [1.0]               0  "
      ]
     },
     "execution_count": 1163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data # test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMS = 16\n",
    "DENSE_UNITS = 64\n",
    "DROPOUT_PCT = 0.0\n",
    "ALPHA = 0.0\n",
    "NUM_CLASSES=data[\"movie\"].max() + 2\n",
    "LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class MaskedEmbeddingsAggregatorLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, agg_mode='sum', **kwargs):\n",
    "        super(MaskedEmbeddingsAggregatorLayer, self).__init__(**kwargs)\n",
    "\n",
    "        if agg_mode not in ['sum', 'mean']:\n",
    "            raise NotImplementedError('mode {} not implemented!'.format(agg_mode))\n",
    "        self.agg_mode = agg_mode\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        masked_embeddings = tf.ragged.boolean_mask(inputs, mask)\n",
    "        if self.agg_mode == 'sum':\n",
    "            aggregated =  tf.reduce_sum(masked_embeddings, axis=1)\n",
    "        elif self.agg_mode == 'mean':\n",
    "            aggregated = tf.reduce_mean(masked_embeddings, axis=1)\n",
    "        return aggregated\n",
    "    \n",
    "    def get_config(self):\n",
    "        # this is used when loading a saved model that uses a custom layer\n",
    "        return {'agg_mode': self.agg_mode}\n",
    "    \n",
    "class L2NormLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(L2NormLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            inputs = tf.ragged.boolean_mask(inputs, mask).to_tensor()\n",
    "        return tf.math.l2_normalize(inputs, axis=-1)\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"aggregate_embeddings/PartitionedCall_298:0\", shape=(None, 16), dtype=float32)\n",
      "Tensor(\"aggregate_embeddings/PartitionedCall_299:0\", shape=(None, 16), dtype=float32)\n",
      "Tensor(\"aggregate_embeddings/PartitionedCall_300:0\", shape=(None, 16), dtype=float32)\n",
      "Tensor(\"aggregate_embeddings/PartitionedCall_301:0\", shape=(None, 16), dtype=float32)\n",
      "Tensor(\"occupation_36:0\", shape=(None, None), dtype=float32)\n",
      "Model: \"functional_124\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "watch_hist (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "watch_hist_time (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "search_hist (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "example_age (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features_embeddings (Embedding) (None, None, 16)     176         watch_hist[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "labels_embeddings (Embedding)   (None, None, 16)     176         watch_hist_time[0][0]            \n",
      "                                                                 search_hist[0][0]                \n",
      "                                                                 example_age[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "l2_norm_1 (L2NormLayer)         (None, None, 16)     0           features_embeddings[0][0]        \n",
      "                                                                 labels_embeddings[0][0]          \n",
      "                                                                 labels_embeddings[1][0]          \n",
      "                                                                 labels_embeddings[2][0]          \n",
      "__________________________________________________________________________________________________\n",
      "aggregate_embeddings (MaskedEmb (None, 16)           0           l2_norm_1[0][0]                  \n",
      "                                                                 l2_norm_1[1][0]                  \n",
      "                                                                 l2_norm_1[2][0]                  \n",
      "                                                                 l2_norm_1[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 64)           0           aggregate_embeddings[0][0]       \n",
      "                                                                 aggregate_embeddings[1][0]       \n",
      "                                                                 aggregate_embeddings[2][0]       \n",
      "                                                                 aggregate_embeddings[3][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_relu (ReLU)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_relu (ReLU)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           4160        dense_2_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_relu (ReLU)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_batch_norm (BatchNormal (None, 64)           256         dense_3_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_output (Dense)            (None, 11)           715         dense_3_batch_norm[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 13,803\n",
      "Trainable params: 13,675\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#---inputs\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "input_watch_hist = tf.keras.Input(shape=(None, ), name='watch_hist')\n",
    "input_watch_hist_time = tf.keras.layers.Input(shape=(None,), name='watch_hist_time')\n",
    "input_search_hist = tf.keras.layers.Input(shape=(None,), name='search_hist')\n",
    "input_example_age = tf.keras.Input(shape=(None, ), name='example_age')\n",
    "input_occupation = tf.keras.Input(shape=(None, ), name='occupation')\n",
    "\n",
    "\n",
    "#--- layers\n",
    "features_embedding_layer = tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIMS, \n",
    "                                            mask_zero=True, trainable=True, name='features_embeddings')\n",
    "labels_embedding_layer = tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIMS, \n",
    "                                            mask_zero=True, trainable=True, name='labels_embeddings')\n",
    "\n",
    "avg_embeddings = MaskedEmbeddingsAggregatorLayer(agg_mode='mean', name='aggregate_embeddings')\n",
    "\n",
    "dense_1 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_1')\n",
    "dense_2 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_2')\n",
    "dense_3 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_3')\n",
    "l2_norm_1 = L2NormLayer(name='l2_norm_1')\n",
    "\n",
    "dense_output = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.nn.softmax, name='dense_output')\n",
    "\n",
    "#--- features\n",
    "features_embeddings = features_embedding_layer(input_watch_hist)\n",
    "l2_norm_features = l2_norm_1(features_embeddings)\n",
    "avg_features = avg_embeddings(l2_norm_features)\n",
    "\n",
    "labels_watch_embeddings = labels_embedding_layer(input_watch_hist_time)\n",
    "l2_norm_watched = l2_norm_1(labels_watch_embeddings)\n",
    "avg_watched = avg_embeddings(l2_norm_watched)\n",
    "\n",
    "labels_search_embeddings = labels_embedding_layer(input_search_hist)\n",
    "l2_norm_searched = l2_norm_1(labels_search_embeddings)\n",
    "avg_searched = avg_embeddings(l2_norm_searched)\n",
    "\n",
    "labels_example_age_embeddings = labels_embedding_layer(input_example_age)\n",
    "l2_norm_example_age = l2_norm_1(labels_example_age_embeddings)\n",
    "avg_example_age = avg_embeddings(l2_norm_example_age)\n",
    "\n",
    "labels_occupation_embeddings = labels_embedding_layer(input_occupation)\n",
    "l2_norm_occupation = l2_norm_1(labels_occupation_embeddings)\n",
    "avg__occupation = avg_embeddings(l2_norm_occupation)\n",
    "\n",
    "\n",
    "print(avg_features)\n",
    "print(avg_watched)\n",
    "print(avg_searched)\n",
    "print(avg_example_age)\n",
    "print(input_occupation)\n",
    "\n",
    "# 임베딩 벡터들 연결\n",
    "concat_inputs = tf.keras.layers.Concatenate(axis=1)([avg_features,\n",
    "                                                     avg_watched,\n",
    "                                                     avg_searched,\n",
    "                                                     avg_example_age,\n",
    "#                                                      avg__occupation\n",
    "                                                     ])\n",
    "# Dense Layers\n",
    "dense_1_features = dense_1(concat_inputs)\n",
    "dense_1_relu = tf.keras.layers.ReLU(name='dense_1_relu')(dense_1_features)\n",
    "dense_1_batch_norm = tf.keras.layers.BatchNormalization(name='dense_1_batch_norm')(dense_1_relu)\n",
    "\n",
    "dense_2_features = dense_2(dense_1_relu)\n",
    "dense_2_relu = tf.keras.layers.ReLU(name='dense_2_relu')(dense_2_features)\n",
    "# dense_2_batch_norm = tf.keras.layers.BatchNormalization(name='dense_2_batch_norm')(dense_2_relu)\n",
    "\n",
    "dense_3_features = dense_3(dense_2_relu)\n",
    "dense_3_relu = tf.keras.layers.ReLU(name='dense_3_relu')(dense_3_features)\n",
    "dense_3_batch_norm = tf.keras.layers.BatchNormalization(name='dense_3_batch_norm')(dense_3_relu)\n",
    "outputs = dense_output(dense_3_batch_norm)\n",
    "\n",
    "#Optimizer\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "#--- prep model\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[input_watch_hist, \n",
    "            input_watch_hist_time, \n",
    "            input_search_hist,\n",
    "            input_example_age,\n",
    "#             input_occupation,\n",
    "            ],\n",
    "    outputs=[outputs]\n",
    ")\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8913 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 938us/step - loss: 2.1913 - acc: 0.6000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 927us/step - loss: 1.7893 - acc: 0.8000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 865us/step - loss: 1.5729 - acc: 0.8000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 791us/step - loss: 1.3525 - acc: 1.0000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 780us/step - loss: 1.1503 - acc: 1.0000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0050 - acc: 1.0000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8831 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7787 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6857 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 796us/step - loss: 0.5966 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 769us/step - loss: 0.5181 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 784us/step - loss: 0.4440 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 821us/step - loss: 0.3812 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.3279 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2809 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 933us/step - loss: 0.2397 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 770us/step - loss: 0.2041 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1742 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 863us/step - loss: 0.1497 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 940us/step - loss: 0.1300 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 834us/step - loss: 0.1138 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 950us/step - loss: 0.1002 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 779us/step - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 780us/step - loss: 0.0691 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0617 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 923us/step - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 946us/step - loss: 0.0499 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0449 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 968us/step - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 883us/step - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 780us/step - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 770us/step - loss: 0.0254 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 824us/step - loss: 0.0234 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 829us/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 843us/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 845us/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 971us/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 814us/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 868us/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 846us/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 975us/step - loss: 0.0111 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([tf.keras.preprocessing.sequence.pad_sequences(train_data['movie_id']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(train_data['watch_hist_time'], dtype=float),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(train_data['search_hist'], dtype=float) + 1e-10,\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(train_data['example_age'], dtype=float),\n",
    "#            tf.keras.preprocessing.sequence.pad_sequences(train_data['occupation'], dtype=float),\n",
    "           ],train_data['predict_labels'].values,\n",
    "           steps_per_epoch=1, epochs=50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"candidate_generation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1a461370d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict([tf.keras.preprocessing.sequence.pad_sequences(test_data['movie_id']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['watch_hist_time'], dtype=float),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['search_hist'], dtype=float) + 1e-10,\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['example_age'], dtype=float)\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03323323, 0.04705915, 0.03846468, 0.6008853 , 0.04078529,\n",
       "        0.03653717, 0.04297908, 0.03952277, 0.04089409, 0.03757692,\n",
       "        0.0420624 ],\n",
       "       [0.04467057, 0.07143843, 0.05111337, 0.39572582, 0.06613615,\n",
       "        0.04641057, 0.03548903, 0.1128524 , 0.06010652, 0.0472837 ,\n",
       "        0.0687734 ],\n",
       "       [0.03265506, 0.04456531, 0.03621548, 0.6071133 , 0.04086963,\n",
       "        0.03534368, 0.04314659, 0.03943169, 0.04152324, 0.03550074,\n",
       "        0.04363524],\n",
       "       [0.03265506, 0.04456531, 0.03621548, 0.6071133 , 0.04086963,\n",
       "        0.03534368, 0.04314659, 0.03943169, 0.04152324, 0.03550074,\n",
       "        0.04363524]], dtype=float32)"
      ]
     },
     "execution_count": 1170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  4  6  8 10]\n",
      " [ 1  3  4  7  8 10]\n",
      " [ 1  3  4  6  8 10]\n",
      " [ 1  3  4  6  8 10]]\n"
     ]
    }
   ],
   "source": [
    "# candidate generation: \n",
    "###### 각 user당 top-7개의 추천 데이터를 뽑아낸다.\n",
    "N = 6\n",
    "k = np.sort((-pred).argsort()[:,:N])\n",
    "print(k)\n",
    "k = k.flatten()\n",
    "k[k>data[\"movie\"].max()]=0\n",
    "k = np.unique(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 4, 6, 7, 8])"
      ]
     },
     "execution_count": 1172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load candidate_generation \n",
    "model = tf.keras.models.load_model(\n",
    "    'candidate_generation.h5',\n",
    "    custom_objects={\n",
    "        'L2NormLayer':L2NormLayer,\n",
    "        'MaskedEmbeddingsAggregatorLayer':MaskedEmbeddingsAggregatorLayer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id title_d\n",
      "0        1  [3, 2]\n",
      "1        2  [4, 5]\n",
      "2        3     [6]\n",
      "3        4     [6]\n",
      "4        5     [7]\n",
      "5        7  [4, 6]\n",
      "6        8  [9, 5]\n",
      "7        9     [9]\n",
      "8       10     [9]\n"
     ]
    }
   ],
   "source": [
    "movie_data = movies.set_index(['movie_id']).sort_index()\n",
    "movie_data = movie_data.loc[k+1]\n",
    "movie_data[\"title_d\"] = movie_data[\"title\"].map(title2title_encoded)\n",
    "\n",
    "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(\n",
    "    'data/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')\n",
    "\n",
    "get_genres(movie_data, genre_cols)\n",
    "\n",
    "new_data = movie_data.merge(ratings, on='movie_id') # rating 추가\n",
    "\n",
    "genre_occurences = new_data[genre_cols].sum().to_dict()\n",
    "genres_encoded = {x: i for i, x in enumerate(genre_cols)}\n",
    "\n",
    "\n",
    "new_data = new_data[['movie_id', 'user_id', 'rating', 'unix_timestamp', 'all_genres', 'title_d']]\n",
    "new_data['movie_type'] = np.where(new_data['rating'] >= 3, 'like', 'dislike') # 3보다 크면 like\n",
    "\n",
    "\n",
    "genre_list = new_data.groupby(['user_id'])['all_genres'].unique().apply(list).reset_index()\n",
    "genre_list['all_genres']=genre_list['all_genres'].apply(lambda x: list(set(','.join(x))) ) # 중복제거\n",
    "genre_list['all_genres']=genre_list['all_genres'].apply(lambda x:[ x for x in x if x.isdigit() ])\n",
    "\n",
    "new_data = normalize_col(new_data, 'unix_timestamp')\n",
    "timestamp_list = new_data.groupby(['user_id'])['unix_timestamp'].unique().apply(list).reset_index()\n",
    "\n",
    "title_list = new_data.groupby(['user_id'])['title_d'].apply(list).reset_index()\n",
    "print(title_list)\n",
    "dataset = movie_list.pivot(index='user_id', columns='movie_type', values='movie_id').reset_index()\n",
    "dataset.fillna(new_data[\"movie_id\"].max()+1, inplace=True)\n",
    "\n",
    "dataset['like'] =dataset['like'].apply(lambda x: x if type(x) is list else [])\n",
    "dataset['dislike'] =dataset['dislike'].apply(lambda x: x if type(x) is list else [])\n",
    "\n",
    "dataset = pd.merge(dataset, title_list, how='left')\n",
    "dataset = pd.merge(dataset, genre_list, how='left')\n",
    "dataset = pd.merge(dataset, timestamp_list, how='left')\n",
    "\n",
    "dataset['predict_labels'] = dataset['like'].apply(lambda x: int(random.uniform(1,new_data[\"movie_id\"].max()))) #label을 마지막 값으로..\n",
    "\n",
    "dataset['like']=dataset['like'].apply(lambda x: [new_data[\"movie_id\"].max()+1] if x == [] else x)\n",
    "dataset['dislike']=dataset['dislike'].apply(lambda x: [new_data[\"movie_id\"].max()+1] if x == [] else x)\n",
    "train_data=dataset[(dataset.user_id >= 1)&\n",
    "                                  (dataset.user_id <= 5)]\n",
    "test_data=dataset[(dataset.user_id >= 6)&\n",
    "                                  (dataset.user_id <= 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>dislike</th>\n",
       "      <th>like</th>\n",
       "      <th>title_d</th>\n",
       "      <th>all_genres</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[3, 2]</td>\n",
       "      <td>[6, 1, 8]</td>\n",
       "      <td>[0.4823272155954916, 0.3272099816004719]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[2, 7]</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>[5, 6, 2, 1, 8]</td>\n",
       "      <td>[1.0, 0.9943047712588169]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[4, 5, 8]</td>\n",
       "      <td>[0.6559625711672339]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[1, 5, 8]</td>\n",
       "      <td>[0.2124407399567807]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[4, 6]</td>\n",
       "      <td>[4, 5, 6, 2, 1, 8]</td>\n",
       "      <td>[0.0, 0.21964208637201138]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[1, 7]</td>\n",
       "      <td>[9, 5]</td>\n",
       "      <td>[4, 5, 3, 1, 8]</td>\n",
       "      <td>[0.5193146561727731, 0.7694933118780622]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[4, 5, 3]</td>\n",
       "      <td>[0.6606054505013651]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[4, 5, 3]</td>\n",
       "      <td>[0.29119399936282336]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id dislike    like title_d          all_genres  \\\n",
       "0        1     [3]     [5]  [3, 2]           [6, 1, 8]   \n",
       "1        2    [10]  [2, 7]  [4, 5]     [5, 6, 2, 1, 8]   \n",
       "2        3    [10]     [3]     [6]           [4, 5, 8]   \n",
       "3        5     [4]    [10]     [7]           [1, 5, 8]   \n",
       "4        7    [10]     [2]  [4, 6]  [4, 5, 6, 2, 1, 8]   \n",
       "5        8    [10]  [1, 7]  [9, 5]     [4, 5, 3, 1, 8]   \n",
       "6        9     [1]    [10]     [9]           [4, 5, 3]   \n",
       "7       10     [1]    [10]     [9]           [4, 5, 3]   \n",
       "\n",
       "                             unix_timestamp  predict_labels  \n",
       "0  [0.4823272155954916, 0.3272099816004719]               1  \n",
       "1                 [1.0, 0.9943047712588169]               1  \n",
       "2                      [0.6559625711672339]               8  \n",
       "3                      [0.2124407399567807]               1  \n",
       "4                [0.0, 0.21964208637201138]               8  \n",
       "5  [0.5193146561727731, 0.7694933118780622]               4  \n",
       "6                      [0.6606054505013651]               8  \n",
       "7                     [0.29119399936282336]               7  "
      ]
     },
     "execution_count": 1176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>dislike</th>\n",
       "      <th>like</th>\n",
       "      <th>title_d</th>\n",
       "      <th>all_genres</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[3, 2]</td>\n",
       "      <td>[6, 1, 8]</td>\n",
       "      <td>[0.4823272155954916, 0.3272099816004719]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[2, 7]</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>[5, 6, 2, 1, 8]</td>\n",
       "      <td>[1.0, 0.9943047712588169]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[4, 5, 8]</td>\n",
       "      <td>[0.6559625711672339]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[1, 5, 8]</td>\n",
       "      <td>[0.2124407399567807]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id dislike    like title_d       all_genres  \\\n",
       "0        1     [3]     [5]  [3, 2]        [6, 1, 8]   \n",
       "1        2    [10]  [2, 7]  [4, 5]  [5, 6, 2, 1, 8]   \n",
       "2        3    [10]     [3]     [6]        [4, 5, 8]   \n",
       "3        5     [4]    [10]     [7]        [1, 5, 8]   \n",
       "\n",
       "                             unix_timestamp  predict_labels  \n",
       "0  [0.4823272155954916, 0.3272099816004719]               1  \n",
       "1                 [1.0, 0.9943047712588169]               1  \n",
       "2                      [0.6559625711672339]               8  \n",
       "3                      [0.2124407399567807]               1  "
      ]
     },
     "execution_count": 1177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>dislike</th>\n",
       "      <th>like</th>\n",
       "      <th>title_d</th>\n",
       "      <th>all_genres</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[4, 6]</td>\n",
       "      <td>[4, 5, 6, 2, 1, 8]</td>\n",
       "      <td>[0.0, 0.21964208637201138]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[1, 7]</td>\n",
       "      <td>[9, 5]</td>\n",
       "      <td>[4, 5, 3, 1, 8]</td>\n",
       "      <td>[0.5193146561727731, 0.7694933118780622]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[4, 5, 3]</td>\n",
       "      <td>[0.6606054505013651]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id dislike    like title_d          all_genres  \\\n",
       "4        7    [10]     [2]  [4, 6]  [4, 5, 6, 2, 1, 8]   \n",
       "5        8    [10]  [1, 7]  [9, 5]     [4, 5, 3, 1, 8]   \n",
       "6        9     [1]    [10]     [9]           [4, 5, 3]   \n",
       "\n",
       "                             unix_timestamp  predict_labels  \n",
       "4                [0.0, 0.21964208637201138]               8  \n",
       "5  [0.5193146561727731, 0.7694933118780622]               4  \n",
       "6                      [0.6606054505013651]               8  "
      ]
     },
     "execution_count": 1178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[\"movie_id\"].max() + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMS = 16\n",
    "DENSE_UNITS = 64\n",
    "DROPOUT_PCT = 0.0\n",
    "ALPHA = 0.0\n",
    "NUM_CLASSES=new_data[\"movie_id\"].max() + 3\n",
    "LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---inputs\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "input_title = tf.keras.Input(shape=(None, ), name='movie_name')\n",
    "inp_video_liked = tf.keras.layers.Input(shape=(None,), name='like')\n",
    "inp_video_disliked = tf.keras.layers.Input(shape=(None,), name='dislike')\n",
    "input_genre = tf.keras.Input(shape=(None, ), name='genre')\n",
    "input_timestamp = tf.keras.Input(shape=(None, ), name='timestamp')\n",
    "\n",
    "\n",
    "#--- layers\n",
    "features_embedding_layer = tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIMS, \n",
    "                                            mask_zero=True, trainable=True, name='features_embeddings')\n",
    "labels_embedding_layer = tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIMS, \n",
    "                                            mask_zero=True, trainable=True, name='labels_embeddings')\n",
    "\n",
    "avg_embeddings = MaskedEmbeddingsAggregatorLayer(agg_mode='mean', name='aggregate_embeddings')\n",
    "\n",
    "dense_1 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_1')\n",
    "dense_2 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_2')\n",
    "dense_3 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_3')\n",
    "l2_norm_1 = L2NormLayer(name='l2_norm_1')\n",
    "\n",
    "dense_output = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.nn.softmax, name='dense_output')\n",
    "\n",
    "#--- features\n",
    "features_embeddings = features_embedding_layer(input_title)\n",
    "l2_norm_features = l2_norm_1(features_embeddings)\n",
    "avg_features = avg_embeddings(l2_norm_features)\n",
    "\n",
    "labels_liked_embeddings = labels_embedding_layer(inp_video_liked)\n",
    "l2_norm_liked = l2_norm_1(labels_liked_embeddings)\n",
    "avg_liked = avg_embeddings(l2_norm_liked)\n",
    "\n",
    "labels_disliked_embeddings = labels_embedding_layer(inp_video_disliked)\n",
    "l2_norm_disliked = l2_norm_1(labels_disliked_embeddings)\n",
    "avg_disliked = avg_embeddings(l2_norm_disliked)\n",
    "\n",
    "labels_genre_embeddings = labels_embedding_layer(input_genre)\n",
    "l2_norm_genre = l2_norm_1(labels_genre_embeddings)\n",
    "avg_genre = avg_embeddings(l2_norm_genre)\n",
    "\n",
    "labels_timestamp_embeddings = labels_embedding_layer(input_timestamp)\n",
    "l2_norm_timestamp = l2_norm_1(labels_timestamp_embeddings)\n",
    "avg_timestamp = avg_embeddings(l2_norm_timestamp)\n",
    "\n",
    "\n",
    "# 임베딩 벡터들 연결\n",
    "concat_inputs = tf.keras.layers.Concatenate(axis=1)([avg_features,\n",
    "                                                     avg_liked,\n",
    "                                                     avg_disliked,\n",
    "                                                     avg_genre,\n",
    "                                                     avg_timestamp\n",
    "                                                     ])\n",
    "# Dense Layers\n",
    "dense_1_features = dense_1(concat_inputs)\n",
    "dense_1_relu = tf.keras.layers.ReLU(name='dense_1_relu')(dense_1_features)\n",
    "dense_1_batch_norm = tf.keras.layers.BatchNormalization(name='dense_1_batch_norm')(dense_1_relu)\n",
    "\n",
    "dense_2_features = dense_2(dense_1_relu)\n",
    "dense_2_relu = tf.keras.layers.ReLU(name='dense_2_relu')(dense_2_features)\n",
    "# dense_2_batch_norm = tf.keras.layers.BatchNormalization(name='dense_2_batch_norm')(dense_2_relu)\n",
    "\n",
    "dense_3_features = dense_3(dense_2_relu)\n",
    "dense_3_relu = tf.keras.layers.ReLU(name='dense_3_relu')(dense_3_features)\n",
    "dense_3_batch_norm = tf.keras.layers.BatchNormalization(name='dense_3_batch_norm')(dense_3_relu)\n",
    "outputs = dense_output(dense_3_batch_norm)\n",
    "\n",
    "#Optimizer\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "#--- prep model\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[input_title, \n",
    "            inp_video_liked, \n",
    "            inp_video_disliked,\n",
    "            input_genre,\n",
    "            input_timestamp,\n",
    "            ],\n",
    "    outputs=[outputs]\n",
    ")\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8788 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0291 - acc: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 930us/step - loss: 1.6379 - acc: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 970us/step - loss: 1.3614 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 905us/step - loss: 1.1594 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 752us/step - loss: 1.0017 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 849us/step - loss: 0.8557 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7315 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6408 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5494 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 983us/step - loss: 0.4636 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 813us/step - loss: 0.3947 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 911us/step - loss: 0.3412 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2924 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 894us/step - loss: 0.2465 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.2052 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1719 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 801us/step - loss: 0.1458 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 865us/step - loss: 0.1262 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 923us/step - loss: 0.1106 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 943us/step - loss: 0.0966 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 851us/step - loss: 0.0839 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 892us/step - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.0644 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 837us/step - loss: 0.0571 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 804us/step - loss: 0.0508 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0451 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0399 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0352 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 948us/step - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 886us/step - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 828us/step - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 835us/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 818us/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 759us/step - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 790us/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 797us/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 976us/step - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 824us/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 828us/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 878us/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 802us/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 983us/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 893us/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 814us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 881us/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 862us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 799us/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 828us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 818us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 854us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 846us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 832us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 784us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 745us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 836us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 934us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 858us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 774us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 786us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 946us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 898us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 817us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 798us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 948us/step - loss: 0.0033 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([tf.keras.preprocessing.sequence.pad_sequences(train_data['title_d']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(train_data['like']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(train_data['dislike']),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(train_data['all_genres']),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(train_data['unix_timestamp'], dtype=float) + 1e-10,\n",
    "           ],train_data['predict_labels'].values,\n",
    "           steps_per_epoch=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x1a4a8f6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0888 - acc: 0.3333\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate([tf.keras.preprocessing.sequence.pad_sequences(test_data['title_d']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['like']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['dislike']),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(test_data['all_genres']),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(test_data['unix_timestamp'], dtype=float) + 1e-10,\n",
    "           ], test_data['predict_labels'].values, verbose=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1a4c024488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict([tf.keras.preprocessing.sequence.pad_sequences(test_data['title_d']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['like']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['dislike']),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(test_data['all_genres']),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(test_data['unix_timestamp'], dtype=float) + 1e-10\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07525565, 0.02337966, 0.07705533, 0.09420496, 0.06743241,\n",
       "        0.07388986, 0.0750409 , 0.05455001, 0.2532599 , 0.0546343 ,\n",
       "        0.08029357, 0.07100342],\n",
       "       [0.09006105, 0.03391625, 0.07724374, 0.10065082, 0.06602372,\n",
       "        0.07904252, 0.07099923, 0.05412571, 0.21223558, 0.05500762,\n",
       "        0.09367954, 0.06701417],\n",
       "       [0.06919657, 0.18517745, 0.07539512, 0.08832996, 0.06528492,\n",
       "        0.07524402, 0.07267001, 0.05677502, 0.11355842, 0.05129936,\n",
       "        0.07687893, 0.07019021]], dtype=float32)"
      ]
     },
     "execution_count": 1185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 8 0]\n",
      " [3 8 0]\n",
      " [1 3 8]]\n"
     ]
    }
   ],
   "source": [
    "# ranking\n",
    "###### 각 user당 top-3개의 추천 데이터를 뽑아낸다.\n",
    "N = 3\n",
    "k = np.sort((-pred).argsort()[:,:N])\n",
    "k[k>new_data[\"movie_id\"].max()]=0\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
