{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# data 읽기\n",
    "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv(\n",
    "    'data/u.user', sep='|', names=users_cols, encoding='latin-1')\n",
    "\n",
    "watch_cols = ['user_id', 'movie_id', 'watch_hist_time']\n",
    "watches = pd.read_csv(\n",
    "    'data/u.watch', sep='\\t', names=watch_cols, encoding='latin-1')\n",
    "\n",
    "search_cols = ['user', 'search_hist']\n",
    "searches = pd.read_csv(\n",
    "    'data/u.search', sep='\\t', names=search_cols, encoding='latin-1')\n",
    "\n",
    "# The movies file contains a binary feature for each genre.\n",
    "genre_cols = [\n",
    "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\",\n",
    "]\n",
    "movies_cols = [\n",
    "    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
    "] + genre_cols\n",
    "movies = pd.read_csv(\n",
    "    'data/u.item', sep='|', names=movies_cols, encoding='latin-1')\n",
    "\n",
    "# Since the ids start at 1, we shift them to start at 0.\n",
    "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\n",
    "watches[\"movie_id\"] = watches[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "watches[\"user_id\"] = watches[\"user_id\"].apply(lambda x: str(x-1))\n",
    "searches[\"user_id\"] = searches[\"user\"].apply(lambda x: str(x-1))\n",
    "# example_age 추가\n",
    "movies['example_age'] = (pd.to_datetime(\"now\") - pd.to_datetime(movies['release_date']))\\\n",
    "            /np.timedelta64(1,'D') \n",
    "movies = normalize_col(movies,'example_age')\n",
    "\n",
    "watches = normalize_col(watches,'watch_hist_time')\n",
    "\n",
    "\n",
    "# data 합치기\n",
    "data = watches.merge(movies, on='movie_id').merge(users, on='user_id')\n",
    "data['user_id']=data['user_id'].astype(int)\n",
    "data['movie_id']=data['movie_id'].astype(int)\n",
    "data = data.set_index(['user_id']).sort_index()\n",
    "data = data.reset_index()\n",
    "data['movie_name']=data['title'].str[:-6] # 년도 부분 자르기\n",
    "\n",
    "\n",
    "def normalize_col(df,col_name):\n",
    "    df[col_name] = (df[col_name] - df[col_name].min()) / (df[col_name].max() - df[col_name].min())\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 유저 인덱스 인코딩\n",
    "user_ids = data[\"user_id\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "# 영화 인덱스 인코딩\n",
    "movie_ids = data[\"movie_id\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "\n",
    "# 영화 제목 인코딩\n",
    "title_ids = data[\"title\"].unique().tolist()\n",
    "title2title_encoded = {x: i for i, x in enumerate(title_ids)}\n",
    "title_encoded2title = {i: x for i, x in enumerate(title_ids)}\n",
    "\n",
    "# 인덱스 번호로 바꾸기\n",
    "data[\"user\"] = data[\"user_id\"].map(user2user_encoded)\n",
    "data[\"movie\"] = data[\"movie_id\"].map(movie2movie_encoded)\n",
    "data[\"title_d\"] = data[\"title\"].map(title2title_encoded)\n",
    "\n",
    "\n",
    "watch_hist = data.groupby(['user'])['movie_id'].apply(list).reset_index()\n",
    "search_hist = searches.groupby(['user'])['search_hist'].apply(list).reset_index()\n",
    "watch_hist_time = data.groupby(['user'])['watch_hist_time'].apply(list).reset_index()\n",
    "example_age = data.groupby(['user'])['example_age'].apply(list).reset_index()\n",
    "\n",
    "user_video_list = data.pivot(index='user_id', columns='movie_id', values='movie').reset_index()\n",
    "user_video_list.fillna(data[\"movie_id\"].max()+1, inplace=True)\n",
    "\n",
    "sample_data=data[['user','occupation','sex']]\n",
    "sample_data=sample_data.reset_index()\n",
    "sample_data = sample_data.drop('index',axis=1)\n",
    "sample_data = sample_data.drop_duplicates()\n",
    "\n",
    "user_movie_list = pd.merge(sample_data,watch_hist, how= 'left')\n",
    "user_movie_list = pd.merge(user_movie_list,watch_hist_time, how='left')\n",
    "user_movie_list = pd.merge(user_movie_list,search_hist, how='left')\n",
    "user_movie_list = pd.merge(user_movie_list,example_age, how='left')\n",
    "user_movie_list['search_hist'] = user_movie_list['search_hist'].apply(lambda x: x if type(x) is list else []) # NaN 처리\n",
    "user_movie_list['predict_labels'] = user_movie_list['movie_id'].apply(lambda x: int(random.uniform(0,data[\"movie\"].max()))) #label을 마지막 값으로..\n",
    "\n",
    "\n",
    "\n",
    "train_data = user_movie_list[(user_movie_list.user >= 1)&\n",
    "                                  (user_movie_list.user <= 5)]\n",
    "test_data = user_movie_list[(user_movie_list.user >= 6)&\n",
    "                                  (user_title_list.user <= 10)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>genre_unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>year</th>\n",
       "      <th>example_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GoldenEye (2011)</td>\n",
       "      <td>01-Jan-2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.359982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Four Rooms (2020)</td>\n",
       "      <td>01-Jan-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Copycat (1998)</td>\n",
       "      <td>01-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.879969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Yao+a+yao+yao+dao+wai...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Twelve Monkeys (2018)</td>\n",
       "      <td>01-Jan-2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Twelve%20Monk...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.079947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Babe%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Dead Man Walking (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Dead%20Man%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Richard III (1995)</td>\n",
       "      <td>22-Jan-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Richard%20III...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.957726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              title release_date  \\\n",
       "0        0                                   Toy Story (1995)  01-Jan-1995   \n",
       "1        1                                   GoldenEye (2011)  01-Jan-2011   \n",
       "2        2                                  Four Rooms (2020)  01-Jan-2020   \n",
       "3        3                                  Get Shorty (1995)  01-Jan-1995   \n",
       "4        4                                     Copycat (1998)  01-Jan-1998   \n",
       "5        5  Shanghai Triad (Yao a yao yao dao waipo qiao) ...  01-Jan-1995   \n",
       "6        6                              Twelve Monkeys (2018)  01-Jan-2018   \n",
       "7        7                                        Babe (1995)  01-Jan-1995   \n",
       "8        8                            Dead Man Walking (1995)  01-Jan-1995   \n",
       "9        9                                 Richard III (1995)  22-Jan-1996   \n",
       "\n",
       "   video_release_date                                           imdb_url  \\\n",
       "0                 NaN  http://us.imdb.com/M/title-exact?Toy%20Story%2...   \n",
       "1                 NaN  http://us.imdb.com/M/title-exact?GoldenEye%20(...   \n",
       "2                 NaN  http://us.imdb.com/M/title-exact?Four%20Rooms%...   \n",
       "3                 NaN  http://us.imdb.com/M/title-exact?Get%20Shorty%...   \n",
       "4                 NaN  http://us.imdb.com/M/title-exact?Copycat%20(1998)   \n",
       "5                 NaN  http://us.imdb.com/Title?Yao+a+yao+yao+dao+wai...   \n",
       "6                 NaN  http://us.imdb.com/M/title-exact?Twelve%20Monk...   \n",
       "7                 NaN     http://us.imdb.com/M/title-exact?Babe%20(1995)   \n",
       "8                 NaN  http://us.imdb.com/M/title-exact?Dead%20Man%20...   \n",
       "9                 NaN  http://us.imdb.com/M/title-exact?Richard%20III...   \n",
       "\n",
       "   genre_unknown  Action  Adventure  Animation  Children  ...  Horror  \\\n",
       "0              0       0          0          1         1  ...       0   \n",
       "1              0       1          1          0         0  ...       0   \n",
       "2              0       0          0          0         0  ...       0   \n",
       "3              0       1          0          0         0  ...       0   \n",
       "4              0       0          0          0         0  ...       0   \n",
       "5              0       0          0          0         0  ...       0   \n",
       "6              0       0          0          0         0  ...       0   \n",
       "7              0       0          0          0         1  ...       0   \n",
       "8              0       0          0          0         0  ...       0   \n",
       "9              0       0          0          0         0  ...       0   \n",
       "\n",
       "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  year  \\\n",
       "0        0        0        0       0         0    0        0  1995   \n",
       "1        0        0        0       0         1    0        0  2011   \n",
       "2        0        0        0       0         1    0        0  2020   \n",
       "3        0        0        0       0         0    0        0  1995   \n",
       "4        0        0        0       0         1    0        0  1998   \n",
       "5        0        0        0       0         0    0        0  1995   \n",
       "6        0        0        0       1         0    0        0  2018   \n",
       "7        0        0        0       0         0    0        0  1995   \n",
       "8        0        0        0       0         0    0        0  1995   \n",
       "9        0        0        0       0         0    1        0  1996   \n",
       "\n",
       "   example_age  \n",
       "0     1.000000  \n",
       "1     0.359982  \n",
       "2     0.000000  \n",
       "3     1.000000  \n",
       "4     0.879969  \n",
       "5     1.000000  \n",
       "6     0.079947  \n",
       "7     1.000000  \n",
       "8     1.000000  \n",
       "9     0.957726  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies # 영화 정보 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>watch_hist_time</th>\n",
       "      <th>search_hist</th>\n",
       "      <th>example_age</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>F</td>\n",
       "      <td>[1, 6]</td>\n",
       "      <td>[0.018896811163116225, 0.174139363982328]</td>\n",
       "      <td>['Shorty', 'Twelve Monkeys']</td>\n",
       "      <td>[0.3599824772752163, 0.07994743182564888]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>writer</td>\n",
       "      <td>M</td>\n",
       "      <td>[2, 7]</td>\n",
       "      <td>[0.1887056559205634, 0.2183194085997988]</td>\n",
       "      <td>['Copycat']</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>technician</td>\n",
       "      <td>M</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>['Twelve Monkeys']</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>other</td>\n",
       "      <td>F</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0.029307554350203404]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>executive</td>\n",
       "      <td>M</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[0.17120860854730763]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  occupation sex movie_id                            watch_hist_time  \\\n",
       "1     1       other   F   [1, 6]  [0.018896811163116225, 0.174139363982328]   \n",
       "2     2      writer   M   [2, 7]   [0.1887056559205634, 0.2183194085997988]   \n",
       "3     3  technician   M      [7]                                      [1.0]   \n",
       "4     4       other   F      [3]                     [0.029307554350203404]   \n",
       "5     5   executive   M      [5]                      [0.17120860854730763]   \n",
       "\n",
       "                    search_hist                                example_age  \\\n",
       "1  ['Shorty', 'Twelve Monkeys']  [0.3599824772752163, 0.07994743182564888]   \n",
       "2                   ['Copycat']                                 [0.0, 1.0]   \n",
       "3            ['Twelve Monkeys']                                      [1.0]   \n",
       "4                            []                                      [1.0]   \n",
       "5                            []                                      [1.0]   \n",
       "\n",
       "   predict_labels  \n",
       "1               0  \n",
       "2               2  \n",
       "3               3  \n",
       "4               8  \n",
       "5               8  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data # train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>watch_hist_time</th>\n",
       "      <th>search_hist</th>\n",
       "      <th>example_age</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>administrator</td>\n",
       "      <td>M</td>\n",
       "      <td>[1, 7]</td>\n",
       "      <td>[0.4177420060364813, 0.1887056559205634]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.3599824772752163, 1.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>administrator</td>\n",
       "      <td>M</td>\n",
       "      <td>[6, 9, 0]</td>\n",
       "      <td>[0.21398888937491797, 0.174139363982328, 0.041...</td>\n",
       "      <td>['Shorty']</td>\n",
       "      <td>[0.07994743182564888, 0.9577264264593144, 1.0]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>student</td>\n",
       "      <td>M</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.22129390665325227]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>M</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user     occupation sex   movie_id  \\\n",
       "6     6  administrator   M     [1, 7]   \n",
       "7     7  administrator   M  [6, 9, 0]   \n",
       "8     8        student   M        [0]   \n",
       "9     9         lawyer   M        [0]   \n",
       "\n",
       "                                     watch_hist_time search_hist  \\\n",
       "6           [0.4177420060364813, 0.1887056559205634]          []   \n",
       "7  [0.21398888937491797, 0.174139363982328, 0.041...  ['Shorty']   \n",
       "8                              [0.22129390665325227]          []   \n",
       "9                                              [0.0]          []   \n",
       "\n",
       "                                      example_age  predict_labels  \n",
       "6                       [0.3599824772752163, 1.0]               3  \n",
       "7  [0.07994743182564888, 0.9577264264593144, 1.0]               7  \n",
       "8                                           [1.0]               5  \n",
       "9                                           [1.0]               8  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data # test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMS = 16\n",
    "DENSE_UNITS = 64\n",
    "DROPOUT_PCT = 0.0\n",
    "ALPHA = 0.0\n",
    "NUM_CLASSES=data[\"movie\"].max() + 3\n",
    "LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class MaskedEmbeddingsAggregatorLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, agg_mode='sum', **kwargs):\n",
    "        super(MaskedEmbeddingsAggregatorLayer, self).__init__(**kwargs)\n",
    "\n",
    "        if agg_mode not in ['sum', 'mean']:\n",
    "            raise NotImplementedError('mode {} not implemented!'.format(agg_mode))\n",
    "        self.agg_mode = agg_mode\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        masked_embeddings = tf.ragged.boolean_mask(inputs, mask)\n",
    "        if self.agg_mode == 'sum':\n",
    "            aggregated =  tf.reduce_sum(masked_embeddings, axis=1)\n",
    "        elif self.agg_mode == 'mean':\n",
    "            aggregated = tf.reduce_mean(masked_embeddings, axis=1)\n",
    "        return aggregated\n",
    "    \n",
    "    def get_config(self):\n",
    "        # this is used when loading a saved model that uses a custom layer\n",
    "        return {'agg_mode': self.agg_mode}\n",
    "    \n",
    "class L2NormLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(L2NormLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            inputs = tf.ragged.boolean_mask(inputs, mask).to_tensor()\n",
    "        return tf.math.l2_normalize(inputs, axis=-1)\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"aggregate_embeddings/PartitionedCall_99:0\", shape=(None, 16), dtype=float32)\n",
      "Tensor(\"aggregate_embeddings/PartitionedCall_100:0\", shape=(None, 16), dtype=float32)\n",
      "Tensor(\"aggregate_embeddings/PartitionedCall_101:0\", shape=(None, 16), dtype=float32)\n",
      "Model: \"functional_39\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "watch_hist (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "watch_hist_time (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "example_age (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features_embeddings (Embedding) (None, None, 16)     192         watch_hist[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "labels_embeddings (Embedding)   (None, None, 16)     192         watch_hist_time[0][0]            \n",
      "                                                                 example_age[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "l2_norm_1 (L2NormLayer)         (None, None, 16)     0           features_embeddings[0][0]        \n",
      "                                                                 labels_embeddings[0][0]          \n",
      "                                                                 labels_embeddings[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "aggregate_embeddings (MaskedEmb (None, 16)           0           l2_norm_1[0][0]                  \n",
      "                                                                 l2_norm_1[1][0]                  \n",
      "                                                                 l2_norm_1[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 48)           0           aggregate_embeddings[0][0]       \n",
      "                                                                 aggregate_embeddings[1][0]       \n",
      "                                                                 aggregate_embeddings[2][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           3136        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_relu (ReLU)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_relu (ReLU)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           4160        dense_2_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_relu (ReLU)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_batch_norm (BatchNormal (None, 64)           256         dense_3_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_output (Dense)            (None, 12)           780         dense_3_batch_norm[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 12,876\n",
      "Trainable params: 12,748\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#---inputs\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "input_watch_hist = tf.keras.Input(shape=(None, ), name='watch_hist')\n",
    "input_watch_hist_time = tf.keras.layers.Input(shape=(None,), name='watch_hist_time')\n",
    "# input_search_hist = tf.keras.layers.Input(shape=(None,), name='search_hist')\n",
    "input_example_age = tf.keras.Input(shape=(None, ), name='example_age')\n",
    "# input_occupation = tf.keras.Input(shape=(None, ), name='occupation')\n",
    "\n",
    "\n",
    "#--- layers\n",
    "features_embedding_layer = tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIMS, \n",
    "                                            mask_zero=True, trainable=True, name='features_embeddings')\n",
    "labels_embedding_layer = tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIMS, \n",
    "                                            mask_zero=True, trainable=True, name='labels_embeddings')\n",
    "\n",
    "avg_embeddings = MaskedEmbeddingsAggregatorLayer(agg_mode='mean', name='aggregate_embeddings')\n",
    "\n",
    "dense_1 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_1')\n",
    "dense_2 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_2')\n",
    "dense_3 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_3')\n",
    "l2_norm_1 = L2NormLayer(name='l2_norm_1')\n",
    "\n",
    "dense_output = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.nn.softmax, name='dense_output')\n",
    "\n",
    "#--- features\n",
    "features_embeddings = features_embedding_layer(input_watch_hist)\n",
    "l2_norm_features = l2_norm_1(features_embeddings)\n",
    "avg_features = avg_embeddings(l2_norm_features)\n",
    "\n",
    "labels_watch_embeddings = labels_embedding_layer(input_watch_hist_time)\n",
    "l2_norm_watched = l2_norm_1(labels_watch_embeddings)\n",
    "avg_watched = avg_embeddings(l2_norm_watched)\n",
    "\n",
    "# labels_search_embeddings = labels_embedding_layer(input_search_hist)\n",
    "# l2_norm_searched = l2_norm_1(labels_search_embeddings)\n",
    "# avg_searched = avg_embeddings(l2_norm_searched)\n",
    "\n",
    "labels_example_age_embeddings = labels_embedding_layer(input_example_age)\n",
    "l2_norm_example_age = l2_norm_1(labels_example_age_embeddings)\n",
    "avg_example_age = avg_embeddings(l2_norm_example_age)\n",
    "\n",
    "# labels_occupation_embeddings = labels_embedding_layer(input_occupation)\n",
    "# l2_norm_occupation = l2_norm_1(labels_occupation_embeddings)\n",
    "# avg__occupation = avg_embeddings(l2_norm_occupation)\n",
    "\n",
    "\n",
    "print(avg_features)\n",
    "print(avg_watched)\n",
    "# print(avg_searched)\n",
    "print(avg_example_age)\n",
    "# print(input_occupation)\n",
    "\n",
    "# 임베딩 벡터들 연결\n",
    "concat_inputs = tf.keras.layers.Concatenate(axis=1)([avg_features,\n",
    "                                                     avg_watched,\n",
    "#                                                      avg_searched,\n",
    "                                                     avg_example_age\n",
    "#                                                      avg__occupation\n",
    "                                                     ])\n",
    "# Dense Layers\n",
    "dense_1_features = dense_1(concat_inputs)\n",
    "dense_1_relu = tf.keras.layers.ReLU(name='dense_1_relu')(dense_1_features)\n",
    "dense_1_batch_norm = tf.keras.layers.BatchNormalization(name='dense_1_batch_norm')(dense_1_relu)\n",
    "\n",
    "dense_2_features = dense_2(dense_1_relu)\n",
    "dense_2_relu = tf.keras.layers.ReLU(name='dense_2_relu')(dense_2_features)\n",
    "# dense_2_batch_norm = tf.keras.layers.BatchNormalization(name='dense_2_batch_norm')(dense_2_relu)\n",
    "\n",
    "dense_3_features = dense_3(dense_2_relu)\n",
    "dense_3_relu = tf.keras.layers.ReLU(name='dense_3_relu')(dense_3_features)\n",
    "dense_3_batch_norm = tf.keras.layers.BatchNormalization(name='dense_3_batch_norm')(dense_3_relu)\n",
    "outputs = dense_output(dense_3_batch_norm)\n",
    "\n",
    "#Optimizer\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "#--- prep model\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[input_watch_hist, \n",
    "            input_watch_hist_time, \n",
    "#             input_search_hist,\n",
    "            input_example_age,\n",
    "#             input_occupation,\n",
    "            ],\n",
    "    outputs=[outputs]\n",
    ")\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[0] = 9 is not in [0, 5)\n\t [[{{node functional_39/aggregate_embeddings/PartitionedCall_1/RaggedMask/boolean_mask/GatherV2}}]] [Op:__inference_train_function_41421]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-329-eb42a97e8aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#            tf.keras.preprocessing.sequence.pad_sequences(train_data['occupation']),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m            ],train_data['predict_labels'].values,\n\u001b[0;32m----> 7\u001b[0;31m            steps_per_epoch=1, epochs=100)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[0] = 9 is not in [0, 5)\n\t [[{{node functional_39/aggregate_embeddings/PartitionedCall_1/RaggedMask/boolean_mask/GatherV2}}]] [Op:__inference_train_function_41421]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([tf.keras.preprocessing.sequence.pad_sequences(train_data['movie_id']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(train_data['watch_hist_time']),\n",
    "#            tf.keras.preprocessing.sequence.pad_sequences(train_data['search_hist']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(train_data['example_age'])\n",
    "#            tf.keras.preprocessing.sequence.pad_sequences(train_data['occupation']),\n",
    "           ],train_data['predict_labels'].values,\n",
    "           steps_per_epoch=1, epochs=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.preprocessing.sequence.pad_sequences(train_data['watch_hist_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
