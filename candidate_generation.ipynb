{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv(\n",
    "    'data/u.user', sep='|', names=users_cols, encoding='latin-1')\n",
    "\n",
    "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(\n",
    "    'data/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')\n",
    "\n",
    "# The movies file contains a binary feature for each genre.\n",
    "genre_cols = [\n",
    "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\",\n",
    "]\n",
    "movies_cols = [\n",
    "    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
    "] + genre_cols\n",
    "movies = pd.read_csv(\n",
    "    'data/u.item', sep='|', names=movies_cols, encoding='latin-1')\n",
    "\n",
    "# Since the ids start at 1, we shift them to start at 0.\n",
    "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\n",
    "ratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: str(x-1))\n",
    "ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: str(x-1))\n",
    "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))\n",
    "\n",
    "\n",
    "genre_occurences = movies[genre_cols].sum().to_dict()\n",
    "\n",
    "genres_encoded = {x: i for i, x in enumerate(genre_cols)}\n",
    "\n",
    "\n",
    "\n",
    "def get_genres(movies, genres):\n",
    "    def get_all_genres(gs):\n",
    "        active = [str(genres_encoded[genre]) for genre, g in zip(genres, gs) if g==1]\n",
    "        if len(active) == 0:\n",
    "            return '0'\n",
    "        return ','.join((active))\n",
    "    movies['all_genres'] = [\n",
    "        get_all_genres(gs) for gs in zip(*[movies[genre] for genre in genres])]\n",
    "\n",
    "get_genres(movies, genre_cols) # 각 유저가 본 장르 얻기\n",
    "\n",
    "rating_details_sample = ratings.merge(movies, on='movie_id').merge(users, on='user_id')\n",
    "\n",
    "rating_details_sample['user_id']=rating_details_sample['user_id'].astype(int)\n",
    "rating_details_sample['movie_id']=rating_details_sample['movie_id'].astype(int)\n",
    "rating_details_sample=rating_details_sample.set_index(['user_id','unix_timestamp']).sort_index()\n",
    "rating_details_sample =rating_details_sample.reset_index()\n",
    "\n",
    "rating_details_sample['movie_type']=np.where(rating_details_sample['rating'] >= 3, 'like', 'dislike') # 3보다 크면 like\n",
    "rating_details_sample['movie_name']=rating_details_sample['title'].str[:-6] # 년도 부분 자르기\n",
    "\n",
    "user_ids = rating_details_sample[\"user_id\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "movie_ids = rating_details_sample[\"movie_id\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "\n",
    "\n",
    "title_ids = rating_details_sample[\"movie_name\"].unique().tolist()\n",
    "title2title_encoded = {x: i for i, x in enumerate(title_ids)}\n",
    "title_encoded2title = {i: x for i, x in enumerate(title_ids)}\n",
    "\n",
    "rating_details_sample[\"user\"] = rating_details_sample[\"user_id\"].map(user2user_encoded)\n",
    "rating_details_sample[\"movie\"] = rating_details_sample[\"movie_id\"].map(movie2movie_encoded)\n",
    "rating_details_sample[\"title_d\"] = rating_details_sample[\"movie_name\"].map(title2title_encoded)\n",
    "\n",
    "sample_data=rating_details_sample[['user','occupation','sex']]\n",
    "sample_data=sample_data.reset_index()\n",
    "\n",
    "movie_list = rating_details_sample.groupby(['user','movie_type'])['movie'].apply(list).reset_index()\n",
    "title_list = rating_details_sample.groupby(['user'])['title_d'].apply(list).reset_index()\n",
    "genre_list = rating_details_sample.groupby(['user'])['all_genres'].unique().apply(list).reset_index()\n",
    "\n",
    "# Get the unique set of genre for all the users\n",
    "genre_list['all_genres']=genre_list['all_genres'].apply(lambda x: list(set(','.join(x))) ) # 중복제거\n",
    "genre_list['all_genres']=genre_list['all_genres'].apply(lambda x:[ x for x in x if x.isdigit() ])\n",
    "\n",
    "user_video_list = movie_list.pivot(index='user', columns='movie_type', values='movie').reset_index()\n",
    "user_video_list.fillna(rating_details_sample[\"movie\"].max()+1, inplace=True)\n",
    "\n",
    "sample_data = sample_data.drop('index',axis=1)\n",
    "sample_data = sample_data.drop_duplicates()\n",
    "\n",
    "user_final_list = pd.merge(user_video_list,title_list, how= 'left')\n",
    "user_title_list1 = pd.merge(user_final_list,genre_list, how='left')\n",
    "user_title_list = pd.merge(user_title_list1,sample_data, how='left')\n",
    "\n",
    "user_title_list['like'] =user_title_list['like'].apply(lambda x: x if type(x) is list else [x])\n",
    "user_title_list['dislike'] =user_title_list['dislike'].apply(lambda x: x if type(x) is list else [x])\n",
    "user_title_list['predict_labels'] = user_title_list['like'].apply(lambda x: int(random.uniform(0,rating_details_sample[\"movie\"].max()))) #label을 마지막 값으로..\n",
    "# user_title_list['predict_labels'] = user_title_list['like'].apply(lambda x: (x[-1])) #label을 마지막 값으로..\n",
    "# user_title_list['like']=user_title_list['like'].apply(lambda x: (x[:-1])) # 마지막 인덱스 레이블로 쓰고 제외\n",
    "# user_title_list['like']=user_title_list['like'].apply(lambda x: [rating_details_sample[\"movie\"].max()+2] if x == [] else x)\n",
    "\n",
    "# user_title_list['predict_labels'] = user_title_list['predict_labels'].apply(lambda x: 1 if x == 10 else x)\n",
    "\n",
    "user_title_list_e=user_title_list[(user_title_list.user >= 1)&\n",
    "                                  (user_title_list.user <= 5)]\n",
    "test_data=user_title_list[(user_title_list.user >= 6)&\n",
    "                                  (user_title_list.user <= 9)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>dislike</th>\n",
       "      <th>like</th>\n",
       "      <th>title_d</th>\n",
       "      <th>all_genres</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>[2, 5, 8, 6, 1]</td>\n",
       "      <td>other</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[0, 6]</td>\n",
       "      <td>[0, 6]</td>\n",
       "      <td>[5, 4, 8, 6, 1]</td>\n",
       "      <td>writer</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[4, 8, 5]</td>\n",
       "      <td>technician</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[8, 5, 1]</td>\n",
       "      <td>other</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>executive</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user dislike    like title_d       all_genres  occupation sex  \\\n",
       "1     1    [10]  [4, 5]  [4, 5]  [2, 5, 8, 6, 1]       other   F   \n",
       "2     2    [10]  [0, 6]  [0, 6]  [5, 4, 8, 6, 1]      writer   M   \n",
       "3     3     [6]    [10]     [6]        [4, 8, 5]  technician   M   \n",
       "4     4     [7]    [10]     [7]        [8, 5, 1]       other   F   \n",
       "5     5    [10]     [8]     [8]              [8]   executive   M   \n",
       "\n",
       "   predict_labels  \n",
       "1               2  \n",
       "2               8  \n",
       "3               8  \n",
       "4               3  \n",
       "5               4  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_title_list_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>dislike</th>\n",
       "      <th>like</th>\n",
       "      <th>title_d</th>\n",
       "      <th>all_genres</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "      <th>predict_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>[2, 5, 4, 8, 6, 1]</td>\n",
       "      <td>administrator</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[2, 9, 4]</td>\n",
       "      <td>[2, 9, 4]</td>\n",
       "      <td>[5, 4, 8, 3, 1, 7]</td>\n",
       "      <td>administrator</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "      <td>student</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user dislike       like    title_d          all_genres     occupation sex  \\\n",
       "6     6    [10]     [5, 6]     [5, 6]  [2, 5, 4, 8, 6, 1]  administrator   M   \n",
       "7     7    [10]  [2, 9, 4]  [2, 9, 4]  [5, 4, 8, 3, 1, 7]  administrator   M   \n",
       "8     8     [9]       [10]        [9]           [3, 4, 5]        student   M   \n",
       "9     9     [9]       [10]        [9]           [3, 4, 5]         lawyer   M   \n",
       "\n",
       "   predict_labels  \n",
       "6               8  \n",
       "7               4  \n",
       "8               3  \n",
       "9               2  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMS = 16\n",
    "DENSE_UNITS = 64\n",
    "DROPOUT_PCT = 0.0\n",
    "ALPHA = 0.0\n",
    "NUM_CLASSES=rating_details_sample[\"movie\"].max() + 3\n",
    "LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class MaskedEmbeddingsAggregatorLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, agg_mode='sum', **kwargs):\n",
    "        super(MaskedEmbeddingsAggregatorLayer, self).__init__(**kwargs)\n",
    "\n",
    "        if agg_mode not in ['sum', 'mean']:\n",
    "            raise NotImplementedError('mode {} not implemented!'.format(agg_mode))\n",
    "        self.agg_mode = agg_mode\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        masked_embeddings = tf.ragged.boolean_mask(inputs, mask)\n",
    "        if self.agg_mode == 'sum':\n",
    "            aggregated =  tf.reduce_sum(masked_embeddings, axis=1)\n",
    "        elif self.agg_mode == 'mean':\n",
    "            aggregated = tf.reduce_mean(masked_embeddings, axis=1)\n",
    "        return aggregated\n",
    "    \n",
    "    def get_config(self):\n",
    "        # this is used when loading a saved model that uses a custom layer\n",
    "        return {'agg_mode': self.agg_mode}\n",
    "    \n",
    "class L2NormLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(L2NormLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            inputs = tf.ragged.boolean_mask(inputs, mask).to_tensor()\n",
    "        return tf.math.l2_normalize(inputs, axis=-1)\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---inputs\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "input_title = tf.keras.Input(shape=(None, ), name='movie_name')\n",
    "inp_video_liked = tf.keras.layers.Input(shape=(None,), name='like')\n",
    "inp_video_disliked = tf.keras.layers.Input(shape=(None,), name='dislike')\n",
    "input_genre = tf.keras.Input(shape=(None, ), name='genre')\n",
    "\n",
    "\n",
    "#--- layers\n",
    "features_embedding_layer = tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIMS, \n",
    "                                            mask_zero=True, trainable=True, name='features_embeddings')\n",
    "labels_embedding_layer = tf.keras.layers.Embedding(input_dim=NUM_CLASSES, output_dim=EMBEDDING_DIMS, \n",
    "                                            mask_zero=True, trainable=True, name='labels_embeddings')\n",
    "\n",
    "avg_embeddings = MaskedEmbeddingsAggregatorLayer(agg_mode='mean', name='aggregate_embeddings')\n",
    "\n",
    "dense_1 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_1')\n",
    "dense_2 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_2')\n",
    "dense_3 = tf.keras.layers.Dense(units=DENSE_UNITS, name='dense_3')\n",
    "l2_norm_1 = L2NormLayer(name='l2_norm_1')\n",
    "\n",
    "dense_output = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.nn.softmax, name='dense_output')\n",
    "\n",
    "#--- features\n",
    "features_embeddings = features_embedding_layer(input_title)\n",
    "l2_norm_features = l2_norm_1(features_embeddings)\n",
    "avg_features = avg_embeddings(l2_norm_features)\n",
    "\n",
    "labels_liked_embeddings = labels_embedding_layer(inp_video_liked)\n",
    "l2_norm_liked = l2_norm_1(labels_liked_embeddings)\n",
    "avg_liked = avg_embeddings(l2_norm_liked)\n",
    "\n",
    "labels_disliked_embeddings = labels_embedding_layer(inp_video_disliked)\n",
    "l2_norm_disliked = l2_norm_1(labels_disliked_embeddings)\n",
    "avg_disliked = avg_embeddings(l2_norm_disliked)\n",
    "\n",
    "labels_genre_embeddings = labels_embedding_layer(input_genre)\n",
    "l2_norm_genre = l2_norm_1(labels_genre_embeddings)\n",
    "avg_genre = avg_embeddings(l2_norm_genre)\n",
    "\n",
    "\n",
    "# 임베딩 벡터들 연결\n",
    "concat_inputs = tf.keras.layers.Concatenate(axis=1)([avg_features,\n",
    "                                                     avg_liked,\n",
    "                                                     avg_disliked,\n",
    "                                                     avg_genre\n",
    "                                                     ])\n",
    "# Dense Layers\n",
    "dense_1_features = dense_1(concat_inputs)\n",
    "dense_1_relu = tf.keras.layers.ReLU(name='dense_1_relu')(dense_1_features)\n",
    "dense_1_batch_norm = tf.keras.layers.BatchNormalization(name='dense_1_batch_norm')(dense_1_relu)\n",
    "\n",
    "dense_2_features = dense_2(dense_1_relu)\n",
    "dense_2_relu = tf.keras.layers.ReLU(name='dense_2_relu')(dense_2_features)\n",
    "# dense_2_batch_norm = tf.keras.layers.BatchNormalization(name='dense_2_batch_norm')(dense_2_relu)\n",
    "\n",
    "dense_3_features = dense_3(dense_2_relu)\n",
    "dense_3_relu = tf.keras.layers.ReLU(name='dense_3_relu')(dense_3_features)\n",
    "dense_3_batch_norm = tf.keras.layers.BatchNormalization(name='dense_3_batch_norm')(dense_3_relu)\n",
    "outputs = dense_output(dense_3_batch_norm)\n",
    "\n",
    "#Optimizer\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "#--- prep model\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[input_title, inp_video_liked, \n",
    "            inp_video_disliked,\n",
    "            input_genre\n",
    "            ],\n",
    "    outputs=[outputs]\n",
    ")\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9673 - acc: 0.2000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 941us/step - loss: 1.9473 - acc: 0.2000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 911us/step - loss: 1.5298 - acc: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1717 - acc: 0.8000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 795us/step - loss: 0.9016 - acc: 0.8000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.7197 - acc: 0.8000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5864 - acc: 0.8000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 803us/step - loss: 0.4677 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3783 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3052 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 812us/step - loss: 0.2467 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 727us/step - loss: 0.1984 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1570 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1254 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 771us/step - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 957us/step - loss: 0.0833 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0693 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 789us/step - loss: 0.0587 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 775us/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0439 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 907us/step - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 786us/step - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 771us/step - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 840us/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 807us/step - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 840us/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 768us/step - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 859us/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 979us/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 784us/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 769us/step - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 872us/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 825us/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 836us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 938us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 765us/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 776us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 893us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 861us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 980us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 769us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 842us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 921us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 818us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 864us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 807us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 854us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 923us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 828us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 826us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 784us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 859us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 897us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 832us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 962us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 774us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 802us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 857us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 810us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 834us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 873us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 846us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([tf.keras.preprocessing.sequence.pad_sequences(user_title_list_e['title_d']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(user_title_list_e['like']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(user_title_list_e['dislike']),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(user_title_list_e['all_genres'])\n",
    "           ],user_title_list_e['predict_labels'].values,\n",
    "           steps_per_epoch=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7579 - acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate([tf.keras.preprocessing.sequence.pad_sequences(test_data['title_d']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['like']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['dislike']),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(test_data['all_genres'])\n",
    "           ],test_data['predict_labels'].values, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([tf.keras.preprocessing.sequence.pad_sequences(test_data['title_d']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['like']),\n",
    "           tf.keras.preprocessing.sequence.pad_sequences(test_data['dislike']),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(test_data['all_genres'])\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04315177, 0.04824422, 0.03746354, 0.04581976, 0.12655161,\n",
       "        0.0534274 , 0.05523088, 0.05852563, 0.3865711 , 0.044081  ,\n",
       "        0.05478231, 0.04615074],\n",
       "       [0.05005604, 0.07310611, 0.04934212, 0.05543246, 0.22852717,\n",
       "        0.0603537 , 0.06539322, 0.04562678, 0.21067618, 0.04292813,\n",
       "        0.0480547 , 0.07050335],\n",
       "       [0.0562546 , 0.08020632, 0.06767781, 0.14779069, 0.09501302,\n",
       "        0.06685804, 0.06779256, 0.05754537, 0.18131818, 0.04788259,\n",
       "        0.06096609, 0.07069473],\n",
       "       [0.0562546 , 0.08020632, 0.06767781, 0.14779069, 0.09501302,\n",
       "        0.06685804, 0.06779256, 0.05754537, 0.18131818, 0.04788259,\n",
       "        0.06096609, 0.07069473]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "4\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(np.argmax(pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"candidate_generation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# candidate generation: \n",
    "###### 각 user당 top-7개의 추천 데이터를 뽑아낸다.\n",
    "N = 7\n",
    "result = np.sort((-pred).argsort()[:,:N])\n",
    "\n",
    "result = result.flatten()\n",
    "result[result>rating_details_sample[\"movie\"].max()]=0\n",
    "result = np.unique(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = movies.loc[result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>genre_unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>year</th>\n",
       "      <th>all_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>3,4,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GoldenEye (2011)</td>\n",
       "      <td>01-Jan-2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1,2,16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Four Rooms (2020)</td>\n",
       "      <td>01-Jan-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1,5,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Copycat (1998)</td>\n",
       "      <td>01-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>6,8,16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Yao+a+yao+yao+dao+wai...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Twelve Monkeys (2018)</td>\n",
       "      <td>01-Jan-2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Twelve%20Monk...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>8,15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Babe%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>4,5,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Dead Man Walking (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Dead%20Man%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              title release_date  \\\n",
       "0        0                                   Toy Story (1995)  01-Jan-1995   \n",
       "1        1                                   GoldenEye (2011)  01-Jan-2011   \n",
       "2        2                                  Four Rooms (2020)  01-Jan-2020   \n",
       "3        3                                  Get Shorty (1995)  01-Jan-1995   \n",
       "4        4                                     Copycat (1998)  01-Jan-1998   \n",
       "5        5  Shanghai Triad (Yao a yao yao dao waipo qiao) ...  01-Jan-1995   \n",
       "6        6                              Twelve Monkeys (2018)  01-Jan-2018   \n",
       "7        7                                        Babe (1995)  01-Jan-1995   \n",
       "8        8                            Dead Man Walking (1995)  01-Jan-1995   \n",
       "\n",
       "   video_release_date                                           imdb_url  \\\n",
       "0                 NaN  http://us.imdb.com/M/title-exact?Toy%20Story%2...   \n",
       "1                 NaN  http://us.imdb.com/M/title-exact?GoldenEye%20(...   \n",
       "2                 NaN  http://us.imdb.com/M/title-exact?Four%20Rooms%...   \n",
       "3                 NaN  http://us.imdb.com/M/title-exact?Get%20Shorty%...   \n",
       "4                 NaN  http://us.imdb.com/M/title-exact?Copycat%20(1998)   \n",
       "5                 NaN  http://us.imdb.com/Title?Yao+a+yao+yao+dao+wai...   \n",
       "6                 NaN  http://us.imdb.com/M/title-exact?Twelve%20Monk...   \n",
       "7                 NaN     http://us.imdb.com/M/title-exact?Babe%20(1995)   \n",
       "8                 NaN  http://us.imdb.com/M/title-exact?Dead%20Man%20...   \n",
       "\n",
       "   genre_unknown  Action  Adventure  Animation  Children  ...  Horror  \\\n",
       "0              0       0          0          1         1  ...       0   \n",
       "1              0       1          1          0         0  ...       0   \n",
       "2              0       0          0          0         0  ...       0   \n",
       "3              0       1          0          0         0  ...       0   \n",
       "4              0       0          0          0         0  ...       0   \n",
       "5              0       0          0          0         0  ...       0   \n",
       "6              0       0          0          0         0  ...       0   \n",
       "7              0       0          0          0         1  ...       0   \n",
       "8              0       0          0          0         0  ...       0   \n",
       "\n",
       "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  year  all_genres  \n",
       "0        0        0        0       0         0    0        0  1995       3,4,5  \n",
       "1        0        0        0       0         1    0        0  2011      1,2,16  \n",
       "2        0        0        0       0         1    0        0  2020          16  \n",
       "3        0        0        0       0         0    0        0  1995       1,5,8  \n",
       "4        0        0        0       0         1    0        0  1998      6,8,16  \n",
       "5        0        0        0       0         0    0        0  1995           8  \n",
       "6        0        0        0       1         0    0        0  2018        8,15  \n",
       "7        0        0        0       0         0    0        0  1995       4,5,8  \n",
       "8        0        0        0       0         0    0        0  1995           8  \n",
       "\n",
       "[9 rows x 26 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
